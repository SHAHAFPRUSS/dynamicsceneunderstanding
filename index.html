<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">

    <meta property="og:title" content="Dynamic Scene Understanding from Vision-Language Representations"/>
    <meta property="og:url" content=""/>
    <meta property="og:image" content="static/images/og_tag_header_image.jpg"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="630"/>


    <title>Dynamic Scene Understanding</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <link rel="icon" href="static/figures_nsvg/punk.png">

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
</head>
<body>


<section class="publication-header">
    <div class="hero-body">
        <div class="container is-max-widescreen">
            <!-- <div class="columns is-centered"> -->
            <div class="column has-text-centered">
                <h1 class="title is-1 publication-title">Dynamic Scene Understanding from Vision-Language Representations</h1>
            </div>
        </div>
    </div>
</section>

<section class="publication-author-block">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <div class="is-size-3 publication-authors">
                    </div>
                    <div class="is-size-5 publication-authors">
                        <span class="author-block">Shahaf Pruss<sup>1</sup>,</span>
                        <span class="author-block">Morris Alper<sup>1,2</sup>,</span>
                        <span class="author-block">Hadar Averbuch-Elor<sup>1,2</sup>,</span>           
                    </div>
                                        
                    <div class="is-size-6 publication-authors">
                        <span class="author-block">1 - Tel Aviv University</span>
                    </div>
                    <div class="is-size-6 publication-authors">
                        <span class="author-block">2 - Cornell University</span>
                    </div>
                                                    
                    <div class="column has-text-centered">
                        <div class="publication-links">
              
                        <span class="link-block">
                            <a href="https://arxiv.org/abs" target="_blank"
                            class="external-link button is-normal is-rounded">
                            <span class="icon">
                                <i class="ai ai-arxiv"></i>
                            </span>
                            <span>arXiv | Coming Soon</span>
                            </a>
                        </span>

                        <span class="link-block">
                            <a class="external-link button is-normal is-rounded is-disabled" href="https://github.com/">
                                <span class="icon">
                                    <i class="fab fa-github"></i>
                                </span>
                                <span>Code | Coming Soon</span>
                            </a>
                        </span>
                                                </a>
                        </span>

                        </div>
                    </div>

                </div>
            </div>
        </div>
    </div>
</section>

<section class="hero is-small">
    <!-- <div class="hero-body"> -->
    <section class="hero teaser">
        <div class="container is-max-desktop">
            <div class="hero-body">
                <!-- <div id="results-carousel" class="carousel results-carousel"> -->
                <div class="container">
                    <div class="item">
                        <div class="column is-centered has-text-centered">
                            <img class="small-image" src="static/teaser/teaser_04_11.jpg" alt="NeTI"/>
                            <h2 class="subtitle">
                                NeuralSVG generates vector graphics from text prompts with ordered and editable shapes. 
                                Our method supports dynamic conditioning, such as background color, which facilitating the generation 
                                of multiple color palettes for a single learned representation.
                            </h2>
                        </div>
                    </div>
                </div>
                <!--  </div> -->
            </div>
        </div>
        <!--  </div> -->
    </section>

    <section class="section hero is-light">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <!-- div class="item">
                      <p style="margin-bottom: 30px">
                    <video poster="" id="tree" autoplay controls muted loop height="100%">
                      <source src="static/figures/video.mp4"
                      type="video/mp4">
                    </video>
                    </p>
                    </div -->
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                             Images depicting complex, dynamic scenes are challenging to parse automatically, requiring both high-level comprehension of the overall situation and fine-grained identification of participating entities and their interactions. Current approaches use distinct methods tailored to sub-tasks such as Situation Recognition and detection of Human-Human and Human-Object Interactions.
                             However, recent advances in image understanding have often leveraged web-scale vision-language (V&L) representations to obviate task-specific engineering.
                             In this work, we propose a framework for dynamic scene understanding tasks by leveraging knowledge from modern, frozen V&L representations.
                             By framing these tasks in a generic manner - as predicting and parsing structured text, or by directly concatenating representations to the input of existing models - we achieve state-of-the-art results while using a minimal number of trainable parameters relative to existing approaches.
                             Moreover, our analysis of dynamic knowledge of these representations shows that recent, more powerful representations effectively encode dynamic scene semantics, making this approach newly possible.
                             We will release our data, code, and trained models.
                        </p>
                    </div>
                </div>
            </div>
            <!--/ Abstract. -->
        </div>
    </section>

    <!-- <section class="hero is-small">
      <div class="hero-body">
        <div class="container">
          <h2 class="title has-text-centered">Video</h2>
          <center>
            <iframe width="630" height="354" src="" title="YouTube video player" frameborder="0" 
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
            allowfullscreen></iframe>
          </center>
        </div>
      </div>
    </section> -->

    <section class="hero is-small">
        <div class="hero-body">
            <div class="container">
                <h2 class="title has-text-centered">Examples of Text-to-Vector Generation <br> with NeuralSVG
                </h2>
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="column is-centered has-text-centered">
                        <img src="static/figures_nsvg/examples_generation_1.png" alt="generation_1" width="95%"/>
                    </div>
                    <div class="column is-centered has-text-centered">
                        <img src="static/figures_nsvg/examples_generation_2.png" alt="generation_2" width="95%"/>
                    </div>
                    <div class="column is-centered has-text-centered">
                        <img src="static/figures_nsvg/examples_generation_3.png" alt="generation_3" width="95%"/>
                    </div>
                    <div class="column is-centered has-text-centered">
                        <img src="static/figures_nsvg/examples_generation_4.png" alt="generation_4" width="95%"/>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section hero is-light">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">How Does it Work?</h2>
                    <div class="content has-text-justified">
                    </div>
                    <div class="column is-centered has-text-centered">
                        <img class="large-image" src="static/system/method_13_11.jpg" alt="method" />
                    </div>
                    <ul class="column is-centered has-text-justified">
                      <li> We learn an implicit neural representation for generating vector graphics from text prompts. We encode the SVG into the weights of a small MLP network, optimized using an Score Distillation Sampling (SDS).
                      </li>
                      <br>
                      <li> To promote an ordered representation, we use a dropout-based technique to encourages each learned shape to have a meaningful and ordered role in the overall scene.
                      </li>
                      <br>
                      <li> Our neural representation enables inference-time control over the generated asset such as dynamically adjusting the color palette or aspect ratio of the generated SVG, all with a single learned representation.
                      </li>
                      <br>
                    </ul>
                </div>
            </div>
          </p>
        </div>
    </section>

    <section class="section hero">
        <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">What Can it Do?</h2>
                    <div class="content has-text-centered">
                    </div>
                    <h3 class="title is-4">Human-Human Interaction (HHI) – Interactive Visualization</h3>
                    <p class="content has-text-centered">
                         We show results of our method together with various models discussed in the paper, showcasing 100 randomly selected samples in a random order from the Waldo & Wenda test set. For models supporting beam search, the top five beams are displayed, and while the images are downscaled for convenience, the results retain the quality of the original images. For externally hosted images, a URL is provided instead of displaying them directly.
                    </p>
                        <a href="static/html1/viz.html">Human-Human Interaction (HHI)</a>
                </div>
            </div>
            <div id="results-carousel-2" class="carousel results-carousel">
                <div class="column is-centered has-text-centered">
                    <img src="static/figures_nsvg/examples_dropout_rooster.png" alt="dropout_1" width="80%"/>
                </div>
                <div class="column is-centered has-text-centered">
                    <img src="static/figures_nsvg/examples_dropout_avocados.png" alt="dropout_2" width="80%"/>
                </div>
                <div class="column is-centered has-text-centered">
                    <img src="static/figures_nsvg/examples_dropout_sun_hat.png" alt="dropout_3" width="80%"/>
                </div>
                <div class="column is-centered has-text-centered">
                    <img src="static/figures_nsvg/examples_dropout_earth.png" alt="dropout_4" width="80%"/>
                </div>
                <div class="column is-centered has-text-centered">
                    <img src="static/figures_nsvg/examples_dropout_bunny.png" alt="dropout_5" width="80%"/>
                </div>
                <div class="column is-centered has-text-centered">
                    <img src="static/figures_nsvg/examples_dropout_astronaut.png" alt="dropout_6" width="80%"/>
                </div>
            </div>

            <div class="columns is-centered has-text-centered">
              <div class="column is-four-fifths">
                  <div class="content has-text-centered">
                  </div>
                  <h3 class="title is-4">Situation Recognition (SiR) – Interactive Visualization</h3>
                  <p class="content has-text-centered"> 
                    We show results of our method and CoFormer on the imsitu testset, showcasing 100 randomly selected samples in a random order. For convenience, the images are stored in a local folder, and a link is provided to access them.
                  </p>
                  <a href="static/html2/viz.html">Situation Recognition (SiR)</a>
              </div>
          </div>
          <div id="results-carousel-3" class="carousel results-carousel">
              <div class="column is-centered has-text-centered">
                  <img src="static/figures_nsvg/examples_control_color_spaceship.png" alt="colors_1" width="120%"/>
              </div>
              <div class="column is-centered has-text-centered">
                  <img src="static/figures_nsvg/examples_control_color_peacock.png" alt="colors_2" width="120%"/>
              </div>
              <div class="column is-centered has-text-centered">
                  <img src="static/figures_nsvg/examples_control_color_dragon.png" alt="colors_3" width="120%"/>
              </div>
              <div class="column is-centered has-text-centered">
                  <img src="static/figures_nsvg/examples_control_color_sydney.png" alt="colors_4" width="120%"/>
              </div>
              <div class="column is-centered has-text-centered">
                  <img src="static/figures_nsvg/examples_control_color_ming.png" alt="colors_5" width="120%"/>
              </div>
          </div>

          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <div class="content has-text-centered">
                </div>
                <h3 class="title is-4">Grounded Situation Recognition (GSR) - Interactive Visualization</h3>
                <p class="content has-text-centered">
                    We show results of our method and CoFormer on the SWiG testset, showcasing 100 randomly selected samples in a random order. For convenience, all visual results (grounded images and their predictions) are stored in a local folder, with a link provided for access.
                </p>
                <a href="static/html3/viz.html">Grounded Situation Recognition (GSR)</a>
            </div>
        </div>
        <div id="results-carousel-4" class="carousel results-carousel">
            <div class="column is-centered has-text-centered">
                <img src="static/figures_nsvg/examples_aspect_ratio_sportscar.png" alt="mixing_2" width="70%"/>
            </div>
            <div class="column is-centered has-text-centered">
                <img src="static/figures_nsvg/examples_aspect_ratio_dog.png" alt="mixing_3" width="70%"/>
            </div>
            <div class="column is-centered has-text-centered">
                <img src="static/figures_nsvg/examples_aspect_ratio_superman.png" alt="mixing_1" width="70%"/>
            </div>
            <div class="column is-centered has-text-centered">
                <img src="static/figures_nsvg/examples_aspect_ratio_penguin.png" alt="mixing_4" width="70%"/>
            </div>
            <div class="column is-centered has-text-centered">
                <img src="static/figures_nsvg/examples_aspect_ratio_train.png" alt="mixing_5" width="70%"/>
            </div>
            <div class="column is-centered has-text-centered">
                <img src="static/figures_nsvg/examples_aspect_ratio_hat.png" alt="mixing_6" width="70%"/>
            </div>
        </div>

          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <div class="content has-text-centered">
                </div>
                <h3 class="title is-4">Human-Object Interaction (HOI) – Interactive Visualization</h3>
                <p class="content has-text-centered">
                    We show results of our method and PViC on the HICO-DET testset, showcasing 100 randomly selected samples in a random order. For convenience, all visual results are stored in a local folder, with a link provided for access.
                </p>
                <a href="static/html4/viz.html">Human-Object Interaction (HOI)</a>
            </div>
        </div>
        <div id="results-carousel-4" class="carousel results-carousel">
            <div class="column is-centered has-text-centered">
                <img src="static/figures_nsvg/examples_sketches_ballerina.png" alt="sketches_1" width="80%"/>
            </div>
            <div class="column is-centered has-text-centered">
                <img src="static/figures_nsvg/examples_sketches_flamingo.png" alt="sketches_2" width="80%"/>
            </div>
            <div class="column is-centered has-text-centered">
                <img src="static/figures_nsvg/examples_sketches_rose.png" alt="sketches_3" width="80%"/>
            </div>
            <div class="column is-centered has-text-centered">
                <img src="static/figures_nsvg/examples_sketches_boat.png" alt="sketches_4" width="80%"/>
            </div>
            <div class="column is-centered has-text-centered">
                <img src="static/figures_nsvg/examples_sketches_vase.png" alt="sketches_5" width="80%"/>
            </div>
            <div class="column is-centered has-text-centered">
                <img src="static/figures_nsvg/examples_sketches_margarita.png" alt="sketches_6" width="80%"/>
            </div>
        </div>

        </div>
        </div>

    </section>


    <footer class="footer">
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content">
                    <p>
                        This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                        Commons Attribution-ShareAlike 4.0 International License</a>.
                    </p>
                    <p>
                        Website source code based on the <a href="https://nerfies.github.io/"> Nerfies</a> project page.
                        If you want to reuse their <a href="https://github.com/nerfies/nerfies.github.io">source code</a>, please credit them appropriately.
                    </p>
                </div>
            </div>
        </div>
        </div>
    </footer>

</body>
</html>
